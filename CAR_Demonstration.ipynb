{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8CjV9QVTEkWgb1m81bnGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmoon312/2022carevent/blob/main/CAR_Demonstration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap # will use this later"
      ],
      "metadata": {
        "id": "HOpIoCGACMyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Importing Scripts & Setting up Data\n",
        "\n",
        "I've set up a sample dataset based on a project I have with Eric Condie, a colleague here at Georgia Tech. In the paper, we're exploring the extent to which social media captures information about the risk of firm failure not captured in an auditor's going concern opinion.\n",
        "\n",
        "I've anonymized a sample of data that we use in our going concern model, which is what I'll use for this demonstration. The data is available on github, which can be loaded directly into Google Colab.\n",
        "\n",
        "This block of code will load the data, print descriptive statistics, and define a list (xvars) which contains the predictor variables we'll use in our classifier."
      ],
      "metadata": {
        "id": "iTcdxFl4e1w0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0xPSd25IOXh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "# Add code to import data, and then describe it, include \"xvars\"\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/jmoon312/2022carevent/main/GCO_Sample_Data_2022CAR.csv\")\n",
        "\n",
        "print(df.describe().transpose())\n",
        "xvars = ['Tenure','FeeRatio','FirmAge','ZScore','Size','Loss','Leverage',\n",
        "         'ChLeverage','OpCF','Finance','Invest','Returns','Beta','Volatility']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load scikit-learn packages needed to train ML Model\n",
        "For this execise, we're going to train an classifier to predict the likelihood a firm uses a Big 4 auditor. This is not what Eric and I do in our paper; we model failure with is a lot harder than whether or not a Big 4 auditor is used! You're welcome to take this same code and try to predict GCOs (also much harder). \n",
        "\n",
        "The scikit-learn package has many different options for classifiers (Naive Bayes, Random Forests, Boosted ensemble models, etc.). We're going to train a Decision Tree since it's pretty fast.\n",
        "\n",
        "The code below will identify training and testing datasets. I'm doing the bare minimum here (10 iterations, 3-fold cross-validation). Ordinarily I use 5-folds and more iterations), but that takes additional time."
      ],
      "metadata": {
        "id": "6q8q4CGff5hN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# set up some parameters to try #\n",
        "params = {'criterion':['gini','entropy'],\n",
        "          'max_depth':[10,50,100,None],\n",
        "          'random_state':[123],\n",
        "          'class_weight':[None,'balanced']}\n",
        "\n",
        "dt = DecisionTreeClassifier() # Leave this as default\n",
        "train,test = train_test_split(df,train_size=0.80, random_state=123)\n",
        "# 3-fold CV, 10 combos (ordinarily do more)\n",
        "rs = RandomizedSearchCV(dt,param_distributions=params,n_jobs=-1,cv=3,n_iter=10,\n",
        "                        verbose=5) \n",
        "res = rs.fit(train[xvars],train['Big4'])"
      ],
      "metadata": {
        "id": "YrSZ5hxxgk85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Evaluate the model fit\n",
        "We'll quickly look at how the model performed and then move on to feature importance."
      ],
      "metadata": {
        "id": "YNiHZs3wyU3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusin matrix (Rows = True 0/1, Columns = Predicted 0/1):\")\n",
        "print(confusion_matrix(test['Big4'],rs.predict(test[xvars])))\n",
        "print(\"\\n\\nscikit-learn's classification report, which gives information on accuracy, precision, recall, etc.\")\n",
        "print(classification_report(test['Big4'],rs.predict(test[xvars])))\n",
        "print(\"\\n\\nThe search identified this as the best estimator:\")\n",
        "print(res.best_estimator_)"
      ],
      "metadata": {
        "id": "npb9kSW7yit0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Permutation Importance\n",
        "I'll illustrate two approaches to evaluating feature importance. The first, referred to as permutation importance, randomly shuffles each feature and evaluates how much model performance is impacted. \n",
        "\n",
        "Here's an example of implementation, which is largely based on the [scikit-learn documentation](https://scikit-learn.org/stable/modules/permutation_importance.html). For a custom implementation, [see here](https://github.com/azsom/ODSC-East-2022/blob/main/interpretability_in_ML.ipynb)."
      ],
      "metadata": {
        "id": "8LDNEX9B9AKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "metrics = ['balanced_accuracy','precision_macro','recall_macro']\n",
        "r = permutation_importance(rs, test[xvars], test['Big4'],n_repeats=30,\n",
        "                           random_state=123,scoring=metrics)\n",
        "\n",
        "# r is dictionary with an entry for each metric. Each value (of the dictionary \n",
        "# Contains three items: mean importance (by feature), \n",
        "# standard deviation of importance (by feature), and the individual deviations\n",
        "\n",
        "# This loop will print each feature provided it is \"significant\", based on it \n",
        "# being more than 2 standard deviations above 0:\n",
        "print(\"\\n\\n----------------------------------------------------------------------\")\n",
        "print(\"Here are the significant features, in order of importance, by metric:\")\n",
        "for metric in r:\n",
        "    print(f\"{metric}\")\n",
        "    rm = r[metric]\n",
        "    for i in rm.importances_mean.argsort()[::-1]:\n",
        "        if rm.importances_mean[i] - 2 * rm.importances_std[i] > 0:\n",
        "            print(f\"    {xvars[i]:<8}\"\n",
        "                  f\"{rm.importances_mean[i]:.3f}\"\n",
        "                  f\" +/- {rm.importances_std[i]:.3f}\")\n",
        "            \n",
        "print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "print(\"\\n\\n----------------------------------------------------------------------\")\n",
        "print(\"Here are the features that are not significant, in order of importance, by metric:\")\n",
        "for metric in r:\n",
        "    print(f\"{metric}\")\n",
        "    rm = r[metric]\n",
        "    for i in rm.importances_mean.argsort()[::-1]:\n",
        "        if rm.importances_mean[i] - 2 * rm.importances_std[i] <= 0:\n",
        "            print(f\"    {xvars[i]:<8}\"\n",
        "                  f\"{rm.importances_mean[i]:.3f}\"\n",
        "                  f\" +/- {rm.importances_std[i]:.3f}\")            \n",
        "print(\"----------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "FL9Cq1tA9uWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see subtle differences by metric, but for the most part each suggests Size, Tenure, and Firm Age are most important. \n",
        "\n",
        "Plotting these values can also be informative and easier to process. We'll limit this to balanced accuracy ([credit for this approach](https://github.com/azsom/ODSC-East-2022/blob/main/interpretability_in_ML.ipynb))."
      ],
      "metadata": {
        "id": "Y89OJWo7FBcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "metric = 'balanced_accuracy'\n",
        "impts = r[metric]\n",
        "sorted_indcs = impts.importances_mean.argsort()\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.boxplot(impts.importances[sorted_indcs].T,labels=np.array(xvars)[sorted_indcs],vert=False)\n",
        "plt.title(\"Permutation Importances (test set)\")\n",
        "plt.xlabel(f'decrease in {metric}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l4RtUG8-Fom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Evaluating Feature Importance with Shapley Values\n",
        "One significant limitation to the previous analysis is that features are correlated, so permutating a feature doesn't necessarily remove its influence from the model. Note that volatility appears insignificant to the model based on the analysis above, but consider correlations between volatility and the features:\n"
      ],
      "metadata": {
        "id": "qVvq0eTPBXhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train[xvars].corr()['Volatility']) "
      ],
      "metadata": {
        "id": "5E0JvsDGCgHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Volatility is significantly associated with Size, which is highly important. So if Size were excluded from the model, would volatility be important? If one is purely focused on which variables drive model performance, this correlation issue may not be that important, but it's hard to conclude that volatility \"doesn't matter\" from this analysis alone.\n",
        "\n",
        "SHAP values don't fully alleviate this issue, but they do provide more insight into when features may or may not matter. The estimates are based on a cooperative game equilibrium. In essence, in a cooperative game there exists an equilibrium where the outcome is the weighted contributions of each player, with some players adding more or less to a given outcome. This same logic is applied to a trained model, and each prediction is expressed as the sum of individual feature importances.\n",
        "\n",
        "Credit for my (developing) understanding of the intuition behind and how to use SHAP values comes from [this illustration](https://github.com/azsom/ODSC-East-2022/blob/main/interpretability_in_ML.ipynb), which was developed by Professor Andras Zsom (Brown University).\n",
        "\n",
        "The example I provide below was adapted for the Decision Tree model we use, and is based on [this post](https://medium.com/analytics-vidhya/shap-part-3-tree-shap-3af9bcd7cd9b).\n",
        "\n",
        "Below, I first review attributes of the original data and then the structure of what the shap package provides. "
      ],
      "metadata": {
        "id": "RqhP6xc2D_oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "print(type(rs.best_estimator_)) # need to extract the estimator to use with shap (the RandomizedSearchCV object is not supported)\n",
        "mod = rs.best_estimator_ # This is the DecisionTree classifier\n",
        "exp = shap.TreeExplainer(mod,data=None,model_output='raw',feature_names=xvars,\n",
        "                         feature_perturbation='tree_path_dependent') # sets up \"explainer\" using the trained model\n",
        "shap_values = exp.shap_values(test[xvars]) # extracts SHAP values for the holdout (test) sample\n",
        "print(f'Shape of test data: {test[xvars].shape}') # simply the shape of the input matrix\n",
        "print(f'Type of shap values: {type(shap_values)}. Length of the list: {len(shap_values)}.') # two classes\n",
        "print(f'Shape of shap_values: {np.array(shap_values).shape}') # two elements, each with shape matching data matrix"
      ],
      "metadata": {
        "id": "JH1Gb9ZYJeLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With SHAPs, you can examine the influence for individual observations. This could be useful if you had some mechanism to partition observations. For instance, how important is size for firms in industry X?\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "M-ZyHb4BVJuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "print(f\"Recall the mean of Big4 is {train['Big4'].mean()}, which is the 'base value'\")\n",
        "print(\"Looking at Row 0:\")\n",
        "print(test.iloc[0])\n",
        "print(\"Here are the feature importances for this prediction:\")\n",
        "shap.force_plot(exp.expected_value[1], shap_values[1][0], features=test[xvars].iloc[0,:])"
      ],
      "metadata": {
        "id": "kSeeDjw5VWmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also examine summary plots:"
      ],
      "metadata": {
        "id": "6gUiPS_kXFDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values,features=test[xvars])"
      ],
      "metadata": {
        "id": "iHeqbd-SXIsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With two classes the color coding isn't relevant (they are exact inverses), but if you were predicting multiple classes it would be useful. Here's the same plot where we only predict Big4 (Class 1)."
      ],
      "metadata": {
        "id": "mGzBn8LDXUss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values,features=test[xvars],class_inds=[1])"
      ],
      "metadata": {
        "id": "dOt_QduoXejk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last plot we'll generate combines some of the earlier information, plotting the distribution of importances by feature:"
      ],
      "metadata": {
        "id": "Po_jtrAnXv3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values[1],features=test[xvars])"
      ],
      "metadata": {
        "id": "-r0Fjy8-X-kK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}